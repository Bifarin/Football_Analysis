{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e712d7aa-357e-42cb-9829-418fc5f097e1",
   "metadata": {},
   "source": [
    "### Module and Function Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be30ff16-93a6-4921-96ab-904d39c73a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pypyodbc\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "import re\n",
    "import pyodbc\n",
    "import html5lib\n",
    "import csv\n",
    "\n",
    "# # Parameter\n",
    "\n",
    "Last_Round = 'MW_38'\n",
    "Next_Week = 38\n",
    "Upper_Week = 38\n",
    "\n",
    "# select sink database option [\"Az SQL\", \"Bif_Database\"]\n",
    "sink = \"Bif_Database\"\n",
    "\n",
    "\n",
    "# #### Connect to database\n",
    "\n",
    "# ### Az Sql\n",
    "if sink == \"Az SQL\":\n",
    "    SERVER_NAME = 'socceranalyticsgroup.database.windows.net'\n",
    "    DATABASE_NAME = 'eplanalytics'\n",
    "    USERNAME = 'socceranalyticsgroup'\n",
    "    PASSWORD = 'Zador@63'\n",
    "\n",
    "    driver= '{ODBC Driver 17 for SQL Server}'\n",
    "    conn_str = (\n",
    "        f\"Driver={driver};\"\n",
    "        f\"Server=tcp:{SERVER_NAME};\"\n",
    "        f\"Database={DATABASE_NAME};\"\n",
    "        f\"Uid={USERNAME};\"\n",
    "        f\"Pwd={PASSWORD};\"\n",
    "        f\"Encrypt=yes;\"\n",
    "        f\"TrustServerCertificate=no;\"\n",
    "        f\"Connection Timeout=30;\"\n",
    "    )\n",
    "\n",
    "    # Create a pyodbc connection object\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "\n",
    "    # Create a SQLAlchemy engine object\n",
    "    engine = create_engine(\"mssql+pyodbc://\", creator=lambda: conn)\n",
    "\n",
    "\n",
    "# ### Bif On Premise\n",
    "if sink == \"Bif_Database\":\n",
    "    SERVER_NAME = 'WS1\\\\WSBIF'\n",
    "    DATABASE_NAME = 'SoccerAnalysis'\n",
    "    USERNAME = 'WS1\\\\User'\n",
    "    conn= pypyodbc.connect(\"\"\"\n",
    "        Driver={{SQL Server}};\n",
    "        Server={0};\n",
    "        Database={1};\n",
    "        Trusted_Connection=yes;\"\"\".format(SERVER_NAME, DATABASE_NAME))\n",
    "\n",
    "    engine = create_engine(\"mssql+pyodbc://@\"+SERVER_NAME+\"/\"+DATABASE_NAME+\"?trusted_connection=yes&driver=SQL+Server\")\n",
    "\n",
    "\n",
    "\n",
    "# # Renaming some club\n",
    "#creating a class that inherit from the dictionary class for mapping of the name variation\n",
    "class MissingDict(dict):\n",
    "    __missing__ = lambda self, key: key\n",
    "    \n",
    "map_values = {\n",
    "    \"Wolverhampton Wanderers\": \"Wolves\",\n",
    "    \"West Ham United\": \"West Ham\",\n",
    "    \"Tottenham Hotspur\": \"Tottenham\",\n",
    "    \"Nottingham Forest\": \"Nott'ham Forest\",\n",
    "    \"Newcastle United\": \"Newcastle Utd\",\n",
    "    \"Manchester United\": \"Manchester Utd\",\n",
    "    \"Brighton and Hove Albion\": \"Brighton\",\n",
    "    \"Sheffield United\": \"Sheffield Utd\"\n",
    "}\n",
    "mapping = MissingDict(**map_values)\n",
    "\n",
    "\n",
    "# # Functions\n",
    "# return list of all column in sqltable\n",
    "def sourcedestcompare(sqltablename:str, pythondf):\n",
    "    sql_columnlist= \"\"\"  \n",
    "    Select COLUMN_NAME from INFORMATION_SCHEMA.COLUMNS\n",
    "    where TABLE_NAME = '{0}'\n",
    "\n",
    "    \"\"\".format(sqltablename)\n",
    "    \n",
    "    df_sqlcolumnlist = pd.read_sql(sql_columnlist, conn)\n",
    "\n",
    "    # remove the index column coming from database\n",
    "    sqllist = df_sqlcolumnlist[1:].values.tolist()\n",
    "    # convert list of list into list of strings\n",
    "    sqllist = [''.join(ele) for ele in sqllist]\n",
    "    \n",
    "    dflist=pythondf.columns.values.tolist()\n",
    "    \n",
    "    # identify difference between sql table and pydataframe\n",
    "    # what sql has but df doesnt contain\n",
    "    temp = []\n",
    "    for x in sqllist:\n",
    "        if x not in dflist:\n",
    "            temp.append(x)        \n",
    "    print(temp)\n",
    "    # what df contains but sql doesnt have\n",
    "    temp1 = []\n",
    "    for x in dflist:\n",
    "        if x not in sqllist:\n",
    "            temp1.append(x)        \n",
    "    print(temp1)\n",
    "#     return sqllist\n",
    "\n",
    "# rename duplicate field from fbref.com\n",
    "def renameduplicatecolumns(dlist, df: pd.DataFrame):\n",
    "    for ele in dlist:\n",
    "        cols = []\n",
    "        count = 1\n",
    "        for column in df.columns:\n",
    "            if column == ele:\n",
    "                cols.append(f'{ele}_{count}')\n",
    "                count+=1\n",
    "                continue\n",
    "            cols.append(column)\n",
    "        df.columns = cols\n",
    "\n",
    "def add(x,y):\n",
    "    result = x+y\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3151b641-29c8-48f3-b21e-04c2c7d3769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_array_of_tuples(csv_file):\n",
    "    result = []\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header if exists\n",
    "        for row in reader:\n",
    "            # Convert the row into a tuple\n",
    "            result.append(tuple(row))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f6a21-a782-432d-b75a-52433d96ed0a",
   "metadata": {},
   "source": [
    "## Function: player_record_to_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a040d0-9c3c-4733-9c54-037abd20caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_record_to_database(html_identifier, database_table):\n",
    "    standing_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"\n",
    "    data = requests.get(standing_url)\n",
    "    soup = BeautifulSoup(data.text, 'lxml')\n",
    "    standings_table = soup.select('table.stats_table')[0]\n",
    "    links = standings_table.find_all('a')\n",
    "    links = [l.get(\"href\") for l in links]\n",
    "    links = [l for l in links if 'squads' in l]\n",
    "    team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
    "    url_to_remove = 'https://fbref.com/en/squads/18bb7c10/Arsenal-Stats'\n",
    "\n",
    "    team_urls = [url for url in team_urls if url != url_to_remove]\n",
    "    all_squad_record = []\n",
    "\n",
    "\n",
    "    for team_url in team_urls:\n",
    "        team_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\",\" \")\n",
    "\n",
    "        \n",
    "        data = requests.get(team_url)\n",
    "        squad_record = pd.read_html(data.text, match = html_identifier)[0]\n",
    "        squad_record.columns = squad_record.columns.droplevel()\n",
    "        squad_record[\"Club\"] = mapping[team_name]\n",
    "        squad_record.drop(squad_record.tail(2).index, inplace=True)\n",
    "        all_squad_record.append(squad_record)\n",
    "        time.sleep(2)    \n",
    "\n",
    "    all_squad_record_df = pd.concat(all_squad_record)\n",
    "    all_squad_record_df[\"Season\"] = \"2023/2024\"\n",
    "\n",
    "    if html_identifier == \"Goalkeeping \":\n",
    "        RepeatedColumn = ['Save%']\n",
    "        renameduplicatecolumns(RepeatedColumn, all_squad_record_df)\n",
    "    if html_identifier == \"Advanced Goalkeeping \":\n",
    "        RepeatedColumn = ['Att', 'Launch%', 'AvgLen']\n",
    "        renameduplicatecolumns(RepeatedColumn, all_squad_record_df)\n",
    "    if html_identifier == \"Passing \":\n",
    "        RepeatedColumn = ['Cmp','Att','Cmp%']\n",
    "        renameduplicatecolumns(RepeatedColumn, all_squad_record_df)\n",
    "        sourcedestcompare(database_table, all_squad_record_df)\n",
    "    if html_identifier == \"Standard Stats \":\n",
    "        RepeatedColumn = ['Gls','Ast','xG','xAG']\n",
    "        renameduplicatecolumns(RepeatedColumn, all_squad_record_df)\n",
    "        sourcedestcompare(database_table, all_squad_record_df)\n",
    "        all_squad_record_df = all_squad_record_df.drop(['PrgC','PrgP','PrgR'],axis=1)\n",
    "    if html_identifier == \"Goal and Shot Creation \":\n",
    "        RepeatedColumn = ['PassLive','PassDead','TO','Sh','Fld','Def']\n",
    "        renameduplicatecolumns(RepeatedColumn, all_squad_record_df)\n",
    "        sourcedestcompare('PlayerChancesStat', all_squad_record_df)\n",
    "    if html_identifier == \"Defensive Actions \":\n",
    "        RepeatedColumn = ['Tkl']\n",
    "        renameduplicatecolumns(RepeatedColumn, all_squad_record_df)    \n",
    "        sourcedestcompare('PlayerDefensiveactionStat', all_squad_record_df)\n",
    "    \n",
    "    \n",
    "    # Send to database (if i want to replace table add if_exists='replace' to the parameter; if_exists='append' )\n",
    "    all_squad_record_df[\"Round\"] = Last_Round\n",
    "    # if you want to export to dbo then remove the schema parameter\n",
    "    all_squad_record_df.to_sql(database_table, engine, if_exists='replace', schema='refactor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201af394-86b7-43c8-8e91-3d00d7c5eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "csv_file = 'player_record_database_name.csv'\n",
    "player_array_of_tuples = read_csv_to_array_of_tuples(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b0e0d-490a-4006-8367-1d63665b7aed",
   "metadata": {},
   "source": [
    "### Executable: player_record_to_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee50e88-ec3a-4eca-a31c-c1fb7e23387d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29860\\883810909.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sqlcolumnlist = pd.read_sql(sql_columnlist, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Round']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29860\\883810909.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sqlcolumnlist = pd.read_sql(sql_columnlist, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Round']\n",
      "['PrgC', 'PrgP', 'PrgR', 'Matches']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29860\\883810909.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sqlcolumnlist = pd.read_sql(sql_columnlist, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Round']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29860\\883810909.py:93: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sqlcolumnlist = pd.read_sql(sql_columnlist, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Past', 'Press', 'Succ', '%', 'ShSv', 'Round']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for html_identifier, database_table in player_array_of_tuples:\n",
    "    player_record_to_database(html_identifier, database_table)\n",
    "    # pause for 1mins before iterating\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee60b4-9fca-493a-ae43-a0d51f3abb91",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Squad Function: squad_record_to_database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299fc46f-c0af-4ffd-857f-dec7b44fdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_record_to_database(html_identifier, database_table):\n",
    "    data = requests.get(\"https://fbref.com/en/comps/9/Premier-League-Stats\")\n",
    "    squad_record = pd.read_html(data.text, match = html_identifier)[0]\n",
    "    squad_record.columns = squad_record.columns.droplevel()\n",
    "    if html_identifier == \"Squad Goalkeeping \":\n",
    "        RepeatedColumn = ['Save%']\n",
    "        return RepeatedColumn\n",
    "    if html_identifier == \"Squad Advanced Goalkeeping \":\n",
    "        RepeatedColumn = ['Att', 'Launch%', 'AvgLen']\n",
    "        return RepeatedColumn\n",
    "    if html_identifier == \"Squad Passing \":\n",
    "        RepeatedColumn = ['Cmp','Att','Cmp%']\n",
    "        return RepeatedColumn\n",
    "    if html_identifier == \"Squad Standard Stats \":\n",
    "        RepeatedColumn = ['Gls','Ast','xG','xAG']\n",
    "        renameduplicatecolumns(RepeatedColumn, squad_record)\n",
    "        return RepeatedColumn\n",
    "    if html_identifier == \"Goal and Shot Creation \":\n",
    "        RepeatedColumn = ['PassLive','PassDead','TO','Sh','Fld','Def']\n",
    "        return RepeatedColumn\n",
    "    if html_identifier == \"Defensive Actions \":\n",
    "        RepeatedColumn = ['Tkl']\n",
    "        return RepeatedColumn \n",
    "    \n",
    "    if html_identifier in(\"Squad Goalkeeping \", \"Squad Advanced Goalkeeping \", \"Squad Passing \", \"Squad Standard Stats \", \"Goal and Shot Creation \", \"Defensive Actions \"):\n",
    "        renameduplicatecolumns(RepeatedColumn, squad_record)\n",
    "    if html_identifier == \"Squad Standard Stats \":\n",
    "        squad_record = squad_record.drop(['PrgC','PrgP'],axis=1)\n",
    "    squad_record[\"Season\"] = \"2023/2024\"\n",
    "    squad_record[\"Round\"] = Last_Round\n",
    "    squad_record.to_sql(database_table, engine, if_exists='replace', schema='refactor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d76966b-432a-49b5-895d-44e691ed28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "csv_file_squad = 'squad_record_database_name.csv'\n",
    "squad_array_of_tuples = read_csv_to_array_of_tuples(csv_file_squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58905f4-0364-4654-9398-7736a6f86163",
   "metadata": {},
   "source": [
    "### Executable: squad_record_to_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63e23e-4b1d-4626-a281-b07af2323880",
   "metadata": {},
   "outputs": [],
   "source": [
    "for html_identifier, database_table in squad_array_of_tuples:\n",
    "    squad_record_to_database(html_identifier, database_table)\n",
    "    # pause for 1mins before iterating\n",
    "    time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
